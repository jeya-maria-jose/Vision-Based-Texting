<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/Vision-Based-Texting_usingNN/assets/css/style.css?v=bc8347eb46617c811cfe57839735357a3324c5e2">
    <link rel="stylesheet" type="text/css" href="/Vision-Based-Texting_usingNN/assets/css/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

<!-- Begin Jekyll SEO tag v2.3.0 -->
<title>An Artificial Neural Network Based Approach towards Eye Gesture Classification for Texting
</title>
<meta property="og:title" content="Vision-Based-Texting_usingNN" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://jeya-maria-jose.github.io/Vision-Based-Texting_usingNN/" />
<meta property="og:url" content="https://jeya-maria-jose.github.io/Vision-Based-Texting_usingNN/" />
<meta property="og:site_name" content="Vision-Based-Texting_usingNN" />
<script type="application/ld+json">
{"name":"Vision-Based-Texting_usingNN","description":null,"author":null,"@type":"WebSite","url":"https://jeya-maria-jose.github.io/Vision-Based-Texting_usingNN/","image":null,"publisher":null,"headline":"Vision-Based-Texting_usingNN","dateModified":null,"datePublished":null,"sameAs":null,"mainEntityOfPage":null,"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>Vision-Based-Texting_usingNN</h1>
          <h2></h2>
        </header>
        <section id="downloads" class="clearfix">
          
	  
          <a href="https://github.com/jeya-maria-jose/Vision-Based-Texting_usingNN" id="view-on-github" class="button"><span>View on GitHub</span></a>
	  
        </section>
        <hr>
        <section id="main_content">
          
<p>The task of typing using the gestures from the eye like left, right, centre, blink by obtaining the eye images from a camera feed has been worked on in this work. A multi-layered neural network is used to recognize the gestures from our eye and an accuracy of 91.6% has been obtained with the image data that were collected and used. With the recognized gestures, an application that aids people to type only using their eye gestures was developed. This method of texting minimizes the muscle movement for paralyzed people or people who suffer from acute illness who would find it difficult to communicate with any other means. The robustness of the application also proves that it can be applied on any handheld device substituting the normal process of texting using keyboard.</p>

<p>Hardware steup:</p>

<p align="center">
  <img src="images/Untitled.png" width="300" />
</p>

<p>Algorithm:</p>

<p align="center">
  <img src="images/bbea24e7-8175-452d-8e8f-e734a427dba6.jfif" width="350" />
</p>

<p>Final GUI Window:</p>

<p align="center">
  <img src="images/be77002c-f65e-4e7b-a1cc-648dd29f813b.jfif" width="350" />
</p>


        </section>

        <footer>
        
          Vision-Based-Texting_usingNN is maintained by <a href="https://github.com/jeya-maria-jose">jeya-maria-jose</a><br>
        
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.
        </footer>

      </div>
    </div>

    
  </body>
</html>
